# Copyright (C) 2022-Present Indoc Systems
#
# Licensed under the GNU AFFERO GENERAL PUBLIC LICENSE,
# Version 3.0 (the "License") available at https://www.gnu.org/licenses/agpl-3.0.en.html.
# You may not use this file except in compliance with the License.

import io
import os
from datetime import datetime
from datetime import timezone

from aiokafka import AIOKafkaProducer
from fastavro import schema
from fastavro import schemaless_writer

from app.config import ConfigClass
from app.logger import logger


class KakfaProducer:

    producer = None
    schema_path = 'app/commons'
    connected = False

    async def init_connection(self) -> None:
        """
        Summary:
            the function for producer to connect the kafka.
        """

        if self.producer is None:
            logger.info('Initializing the kafka producer')
            self.producer = AIOKafkaProducer(bootstrap_servers=ConfigClass.KAFKA_URL)
            try:
                await self.producer.start()
                self.connected = True
            except Exception as e:
                logger.error(f'Fail to start kafka producer: {e}')

        return

    async def close_connection(self) -> None:
        """
        Summary:
            the function for producer to close the kafka connection.
        """
        if self.producer is not None:
            logger.info('Closing the kafka producer')
            await self.producer.stop()

    async def _send_message(self, topic: str, content: bytes) -> None:
        """
        Summary:
            the function will send the byte message to kafka topic

        Parameter:
            - topic(str): the name of kafka topic
            - content(bytes): the byte message that will be sent to topic
        """

        try:
            await self.producer.send_and_wait(topic, content)
        except Exception as e:
            logger.error(f'Fail to send message: {e}')
            raise e

    async def _validate_message(self, schema_name: str, message: dict) -> bytes:
        """
        Summary:
            the function will validate the dict message with specified schema
            and return the byte message to caller

        Parameter:
            - schema_name(str): the name of kafka topic
            - message(dict): the message generated by service logic

        Return:
            - byte message
        """

        bio = io.BytesIO()
        SCHEMA = schema.load_schema(os.path.join(self.schema_path, schema_name))
        schemaless_writer(bio, SCHEMA, message)

        message = bio.getvalue()

        return message

    async def create_activity_log(
        self, source_node: dict, schema_name: str, operator: str, topic: str, network_origin: str
    ):
        """
        Summary:
            the function will validate the dict message with specified schema
            and return the byte message to caller

        Parameter:
            - source_node(dict): the source node contains item infomation
            - schema_name(str): the name of schema
            - operator(str): the user who take the action
            - topic(str): the target topic that message will be sent into

        Return:
            - byte message
        """

        logger.info(f'Create {operator} activity log to topic: {topic}')

        message = {
            'activity_type': 'upload',
            'activity_time': datetime.now(tz=timezone.utc),
            'item_id': source_node.get('id'),
            'item_type': source_node.get('type'),
            'item_name': source_node.get('name'),
            'item_parent_path': source_node.get('parent_path'),
            'container_code': source_node.get('container_code'),
            'container_type': source_node.get('container_type'),
            'zone': source_node.get('zone'),
            'user': operator,
            'imported_from': '',
            'changes': [],
            'network_origin': network_origin,
        }

        byte_message = await self._validate_message(schema_name, message)
        await self._send_message(topic, byte_message)

        return


kakfa_producer = KakfaProducer()


async def get_kafka_producer() -> KakfaProducer:
    """
    Summary:
        the function will initialize the producer if the function
        is called for first time

    Return:
        - KakfaProducer: the global variable
    """

    await kakfa_producer.init_connection()

    return kakfa_producer
